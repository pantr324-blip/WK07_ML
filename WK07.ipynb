{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 07\n",
        "\n",
        "Regression modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/data_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from data_utils import regression_error\n",
        "from data_utils import object_from_json_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKGt8bzScNA"
      },
      "source": [
        "## Regression\n",
        "\n",
        "Regression, or Regression Analysis, is a set of statistical processes for estimating the relationship between a dependent variable (sometimes called the 'outcome', 'response' or 'label') and one or more independent variables (called 'features', 'dimensions' or 'columns').\n",
        "\n",
        "For example, let's say we have the following data about people's wages and years of experience:\n",
        "\n",
        "<img src=\"./imgs/wages-exp.png\" width=\"620px\"/>\n",
        "\n",
        "We could use regression to calculate how the values for wages are affected by years of experience in our dataset, and then create a function to more generally estimate the relation between wages and experience:\n",
        "\n",
        "<img src=\"./imgs/wages-exp-fit.png\" width=\"620px\"/>\n",
        "\n",
        "We could now estimate wages for values of years of experience that we didn't have measurements for.\n",
        "\n",
        "This is an estimate, but the more points we use and the more features we have in our dataset the better the regression results will be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting up Regression\n",
        "\n",
        "For a simple dataset we can perform regression by following these steps:\n",
        "\n",
        "1. Load dataset\n",
        "2. Encode label features as numbers\n",
        "3. Normalize the data\n",
        "4. Separate the outcome variable(s) (not scaled) and the feature variables (scaled)\n",
        "5. Create a regression model\n",
        "6. Run model on input data and \n",
        "7. Measure error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diamond Prices\n",
        "\n",
        "Let's use the dataset from last week to set up a diamond price estimator.\n",
        "\n",
        "Steps 1 - 3 should look familiar, and they've been pasted below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Load Dataset\n",
        "DIAMONDS_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/diamonds.json\"\n",
        "\n",
        "# Read into DataFrame\n",
        "diamonds_data = object_from_json_url(DIAMONDS_FILE)\n",
        "diamonds_df = pd.DataFrame.from_records(diamonds_data)\n",
        "\n",
        "\n",
        "## 2. Encode non-numeric values\n",
        "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
        "color_order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
        "clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
        "\n",
        "diamond_encoder = OrdinalEncoder(categories=[cut_order, color_order, clarity_order])\n",
        "\n",
        "ccc_vals = diamond_encoder.fit_transform(diamonds_df[[\"cut\", \"color\", \"clarity\"]].values)\n",
        "diamonds_df[[\"cut\", \"color\", \"clarity\"]] = ccc_vals\n",
        "\n",
        "\n",
        "## 3. Normalize the data\n",
        "diamond_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
        "diamonds_scaled_df = diamond_scaler.fit_transform(diamonds_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chose Features\n",
        "\n",
        "Now we separate the outcome variable values and the independent variables.\n",
        "\n",
        "Let's start simple and use only one feature: `carat`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Separate the outcome variable and the independent variables\n",
        "prices = diamonds_df[[\"price\"]]\n",
        "carats = diamonds_scaled_df[[\"carat\"]]\n",
        "\n",
        "# Plot the variables, just for checking\n",
        "plt.scatter(carats, prices, marker='o', linestyle='', alpha=0.3)\n",
        "plt.xlabel(\"carat\")\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model\n",
        "\n",
        "Let's setup and create a linear regression model.\n",
        "\n",
        "We'll use the [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object from the `Scikit-Learn` library.\n",
        "\n",
        "Once we create an instance of a `LinearRegression` object, we can use its `fit()` function to compute the relationship between `price` and `carat` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Create a LinearRegression object\n",
        "price_model = LinearRegression()\n",
        "\n",
        "# Create a model that relates price of diamonds to their carat value\n",
        "price_model.fit(carats, prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do the creation and fitting in one line like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Create a LinearRegression object and fit with the training data\n",
        "price_model = LinearRegression().fit(carats, prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are the $\\beta$ parameters that the model calculated for our line of best fit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "price_model.coef_, price_model.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate\n",
        "\n",
        "It's really rare for a model to perfectly capture all of the subtleties of a dataset. Models try to capture trends in the data and not all data in a dataset is gonna fit a trend.\n",
        "\n",
        "When we run `predict()` on a dataset some/most of the predictions are gonna be off. Since we have the real values and the predicted values we can calculate how far off the predictions are.\n",
        "\n",
        "The simplest and most obvious way to do this is to feed the features from our dataset back into our model, but this time, instead of using them to train our model, we'll compare the computed prediction values to the actual known values of the outcome variables in our dataset.\n",
        "\n",
        "One way to formally quantify this process is to calculate the *Mean Squared Error* of our predictions, or, the average of the squares of individual errors.\n",
        "\n",
        "It's calculated using the known values for the outcome variable $Y$, and the predicted values from our model $\\hat{Y}$. For each prediction, we subtract the predicted value from the known value and square this difference. We do this for every predicted value, and sum all of these squared errors before dividing by the total number of predictions.\n",
        "\n",
        "It can be expressed as:\n",
        "\n",
        "$\\displaystyle \\frac{1}{n} \\sum_{i=1}^{n}\\left(Y_i - \\hat{Y}_i \\right)^{2}$\n",
        "\n",
        "Luckily, the `regression_error()` function does this for us when given the $2$ lists of outcome values, $Y$ and $\\hat{Y}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Run the model on the training data\n",
        "predicted_prices = price_model.predict(carats)\n",
        "\n",
        "## 7. Measure error\n",
        "regression_error(diamonds_df[\"price\"], predicted_prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result\n",
        "\n",
        "Hmmm.... what this means is that on average our model is wrong by $\\$1388$ dollars.\n",
        "\n",
        "We can plot our predictions with the original data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the original values\n",
        "plt.scatter(carats, prices, marker='o', linestyle='', alpha=0.3)\n",
        "plt.xlabel(\"carat\")\n",
        "plt.ylabel(\"price\")\n",
        "\n",
        "# Plot the predictions\n",
        "plt.scatter(carats, predicted_prices, color='r', marker='o', linestyle='', alpha=0.05)\n",
        "plt.xlabel(\"carat\")\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another way to plot this is to draw the line between the predicted values for `carat.min()` and `carat.max()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the original values\n",
        "plt.scatter(carats, prices, marker='o', linestyle='', alpha=0.3)\n",
        "plt.xlabel(\"carat\")\n",
        "plt.ylabel(\"price\")\n",
        "\n",
        "# Plot the line of best fit\n",
        "c0,c1 = carats.min(), carats.max()\n",
        "p0,p1 = price_model.coef_[0]*c0 + price_model.intercept_[0], price_model.coef_[0]*c1 + price_model.intercept_[0]\n",
        "\n",
        "plt.plot([c0,c1], [p0,p1], color=\"r\", linestyle=\"-\", linewidth=4)\n",
        "plt.xlabel(\"carat\")\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "We're only using one variable to model the price using linear regression, so, as the name suggests, the resulting model is a line:\n",
        "\n",
        "$\\displaystyle price = \\beta \\cdot carat$\n",
        "\n",
        "(This should look familiar; it's the equation for a line that we might have learned in algebra: $y = m \\cdot x + b$)\n",
        "\n",
        "$\\beta$ in this equation is a constant calculated by the model. The model uses all of the values about `price` and `carat` to calculate this ONE constant that defines our line.\n",
        "\n",
        "For every value of $carat$ the model gives us a value for $price$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Another Graph\n",
        "\n",
        "Another way to visualize how far off the model is from the actual data is to look at sorted lists of prices.\n",
        "\n",
        "So, we run the model on the input, get the resulting prices, sort them and plot them against the original sorted prices.\n",
        "\n",
        "This is just a quick way to see if there are regions of our data where the model is wrong more often, or right more often. We can combine that information with the distribution of prices in the dataset to see if it's ok for our model to be this wrong.\n",
        "\n",
        "We could have a situation where very rare and uncommon diamond prices (too low or too high) are contributing a large amount of error to our average error. If the predictions for the more common diamond prices are close, then maybe our model is good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prices_original = diamonds_df[\"price\"]\n",
        "\n",
        "# Plot the original and predicted prices\n",
        "plt.plot(sorted(prices_original), marker='o', linestyle='', alpha=0.3)\n",
        "plt.plot(sorted(predicted_prices), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "The model seems ok with lower priced diamonds, but anything more expensive than $\\$6000$ seems to be more wrong.\n",
        "\n",
        "Let's add features to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using more features\n",
        "\n",
        "Let's add a feature to build our model.\n",
        "\n",
        "This time our model equation will have multiple independent variables:\n",
        "\n",
        "$\\displaystyle price = \\beta_0 \\cdot carat + \\beta_1 \\cdot width$\n",
        "\n",
        "The $\\beta_i$ values in this equation are constants that the model calculates. There are $2$ now, so the model has more parameters to adjust in order to get a better fit.\n",
        "\n",
        "The overall process for preparing our data is the same, but this time we'll use `carat` and the `x` dimension of the diamonds to predict their prices.\n",
        "\n",
        "We already have scaled features in `features_scaled_df`, so we can just pick our input features from there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Separate the outcome variable and the independent variables\n",
        "prices = diamonds_df[[\"price\"]]\n",
        "features = diamonds_scaled_df[[\"carat\", \"x\"]]\n",
        "\n",
        "## 5. Create a LinearRegression object and\n",
        "# fit a model that relates price of diamonds to their carat value as well as width and length\n",
        "price_model = LinearRegression().fit(features, prices)\n",
        "\n",
        "## 6. Run the model on the training data\n",
        "predicted_prices = price_model.predict(features)\n",
        "\n",
        "## 7. Measure error\n",
        "regression_error(diamonds_df[\"price\"], predicted_prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The $\\beta$ parameters computed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "price_model.coef_, price_model.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result\n",
        "\n",
        "This is marginally better. The error decreased very slightly.\n",
        "\n",
        "We can plot our new model predictions using a $3D$ plot to look at how price varies along with the `carat` and `width` of the diamonds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "cs = diamonds_df[[\"carat\"]].values\n",
        "xs = diamonds_df[[\"x\"]].values\n",
        "\n",
        "ps = diamonds_df[[\"price\"]].values\n",
        "pps = predicted_prices\n",
        "\n",
        "ax.scatter(cs, xs, ps, marker='o', linestyle='', alpha=0.06)\n",
        "ax.scatter(cs, xs, pps, color='r', marker='o', linestyle='', alpha=0.1)\n",
        "\n",
        "ax.set_xlabel('width')\n",
        "ax.set_ylabel('length')\n",
        "ax.set_zlabel('price')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our line of best fit is still a line. Why?\n",
        "\n",
        "Let's visualize our model by calculating the predicted prices at the smallest and largest values of `carat` and `width`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "cs = diamonds_scaled_df[[\"carat\"]].values\n",
        "xs = diamonds_scaled_df[[\"x\"]].values\n",
        "\n",
        "ps = diamonds_df[[\"price\"]].values\n",
        "pps = predicted_prices\n",
        "\n",
        "ax.scatter(cs, xs, ps, marker='o', linestyle='', alpha=0.05)\n",
        "ax.scatter(cs, xs, pps, color='r', marker='o', linestyle='', alpha=0.05)\n",
        "\n",
        "csmm = [cs.min(), cs.max(), cs.max(), cs.min(), cs.min()]\n",
        "xsmm = [xs.min(), xs.min(), xs.max(), xs.max(), xs.min()]\n",
        "\n",
        "ppsmm = [\n",
        "  price_model.coef_[0][0] * csmm[i] + price_model.coef_[0][1] * xsmm[i] + price_model.intercept_[0] for i in range(len(xsmm))\n",
        "]\n",
        "ax.plot(csmm, xsmm, ppsmm, color='r', marker='o', linestyle='-', alpha=0.5)\n",
        "ax.set_xlabel('width')\n",
        "ax.set_ylabel('length')\n",
        "ax.set_zlabel('price')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that when we use $2$ parameters, the model finds a solutions in larger space, but the model still predicts a line.\n",
        "\n",
        "It's just that now that line lies on a plane through our input range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using more features\n",
        "\n",
        "Let's use a few more features to build our model.\n",
        "\n",
        "This time our model equation will have $3$ independent variables:\n",
        "\n",
        "$\\displaystyle price = \\beta_0 \\cdot carat + \\beta_1 \\cdot width + \\beta_2 \\cdot length$\n",
        "\n",
        "Again, the $\\beta_i$ values in this equation are constants that the model will calculate for us.\n",
        "\n",
        "The overall process for preparing our data is the same, but this time we'll use `carat` along with the `x` and `y` dimensions of the diamond to predict prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Separate the outcome variable and the independent variables\n",
        "prices = diamonds_df[[\"price\"]]\n",
        "features = diamonds_scaled_df[[\"carat\", \"x\", \"y\"]]\n",
        "\n",
        "## 5. Create a LinearRegression object and fit it with training data (carat, width and length)\n",
        "price_model = LinearRegression().fit(features, prices)\n",
        "\n",
        "## 6. Run the model on the training data\n",
        "predicted_prices = price_model.predict(features)\n",
        "\n",
        "## 7. Measure error\n",
        "regression_error(diamonds_df[\"price\"], predicted_prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The $\\beta$ parameters computed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "price_model.coef_, price_model.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result\n",
        "\n",
        "This is getting better. The more features we give the model, the better it's able to find a line/plane/hyperplane to represent the price variable.\n",
        "\n",
        "We can plot our new model, but since we humans are limited to $3$ physical dimensions that we can comprehend, we can't plot price as a function of all $3$ of our features.\n",
        "\n",
        "We'll create a $3D$ plot that to look at how price varies along with the length and width of the diamonds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "xs = diamonds_df[[\"x\"]].values\n",
        "ys = diamonds_df[[\"y\"]].values\n",
        "\n",
        "ps = diamonds_df[[\"price\"]].values\n",
        "pps = predicted_prices\n",
        "\n",
        "ax.scatter(xs, ys, ps, marker='o', linestyle='', alpha=0.05)\n",
        "ax.scatter(xs, ys, pps, color='r', marker='o', linestyle='', alpha=0.1)\n",
        "\n",
        "ax.set_xlabel('width')\n",
        "ax.set_ylabel('length')\n",
        "ax.set_zlabel('price')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using ALL features\n",
        "\n",
        "Let's use all $9$ features from the dataset to build our model.\n",
        "\n",
        "The model equation will be something like:\n",
        "\n",
        "$\\displaystyle price = \\beta_0 \\cdot x_0 + \\beta_1 \\cdot x_1 + ... + \\beta_8 \\cdot x_8$\n",
        "\n",
        "Where the $x_i$ values are the values of our features (`carat`, `width`, etc) and the $\\beta_i$ parameters are the constant values that the model will calculate.\n",
        "\n",
        "Repeat the steps below, but this time using all of the features in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: repeat steps for training a predictor on all features\n",
        "\n",
        "## 4. Separate the outcome variable and the independent variables\n",
        "## 5. Create a LinearRegression object and fit it with training data\n",
        "## 6. Run the model on the training data\n",
        "## 7. Measure error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result\n",
        "\n",
        "The error should have gotten better.\n",
        "\n",
        "Let's sort and plot all of the prices from the original dataset and the reconstructed prices from our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prices_original = diamonds_df[\"price\"]\n",
        "\n",
        "# Plot the original and predicted prices\n",
        "plt.plot(sorted(prices_original), marker='o', linestyle='', alpha=0.3)\n",
        "plt.plot(sorted(predicted_prices), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "This is another one of these graphs of sorted prices that can be used to see the distribution of prices from the dataset and compare it to the prices from the model.\n",
        "\n",
        "Depending on where on the distribution our error comes from, we can have an ok model with large errors, as long as the errors are in regions that aren't common.\n",
        "\n",
        "In this case, there is some pretty constant error throughout the modeled prices.\n",
        "\n",
        "The error is even worse for diamonds on the extreme ends of price: the too cheap and too expensive ones.\n",
        "\n",
        "And since even a small percentage of error for an expensive diamond contributes to a large error in dollars, this is probably where a lot of the error is coming from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Even MORE Features !\n",
        "\n",
        "One trick to improve our model is to create some extra features from the current ones.\n",
        "\n",
        "For example, in addition to considering `carat` and `width` of each diamond separately, we can create a feature that is a combination of these two values.\n",
        "\n",
        "Considering just those $2$ features, instead of having an equation that is like this:\n",
        "\n",
        "$\\displaystyle price = \\beta_0 \\cdot carat + \\beta_1 \\cdot width$\n",
        "\n",
        "We can try to model an equation that has quadratic terms, like this:\n",
        "\n",
        "$\\displaystyle price = \\beta_0 \\cdot carat + \\beta_1 \\cdot width + \\beta_2 \\cdot carat^2 + \\beta_3 \\cdot width^2 + \\beta_4 \\cdot carat \\cdot width$\n",
        "\n",
        "Or even cubic terms:\n",
        "\n",
        "$\\displaystyle price = \\beta_0 \\cdot carat + \\beta_1 \\cdot width + \\beta_2 \\cdot carat^2 + \\beta_3 \\cdot width^2 + \\beta_4 \\cdot carat \\cdot width + \\beta_5 \\cdot carat^3 + \\beta_6 \\cdot width^3$\n",
        "\n",
        "This allows our model to figure out more complex relationships between the features and consider non-linear relationships between features and price (maybe `price` goes up proportional to the square of the `width` of the diamond).\n",
        "\n",
        "Scikit-Learn has an object called [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) that helps us do exactly this. We just have to instantiate it and use it to create some extra features for us.\n",
        "\n",
        "The process of using it should loo familiar by now: instantiate an object, use its `fit_transform()` function on our features to get a new version of our data, use the new data, success."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Separate the outcome variable and the independent variables\n",
        "prices = diamonds_df[[\"price\"]]\n",
        "features = diamonds_scaled_df.drop(columns=[\"price\"])\n",
        "\n",
        "## 4B. Create extra features\n",
        "poly = PolynomialFeatures(degree=3, include_bias=False).set_output(transform=\"pandas\")\n",
        "features_poly = poly.fit_transform(features)\n",
        "\n",
        "## 5. Create a LinearRegression object and fit it with training data\n",
        "price_model = LinearRegression().fit(features_poly, prices)\n",
        "\n",
        "## 6. Run the model on the training data\n",
        "predicted_prices = price_model.predict(features_poly)\n",
        "\n",
        "## 7. Measure error\n",
        "regression_error(diamonds_df[\"price\"], predicted_prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result\n",
        "\n",
        "This is significantly better than our original model.\n",
        "\n",
        "Let's sort and plot the resulting prices again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot sorted prices\n",
        "prices_original = sorted(diamonds_df[\"price\"])\n",
        "prices_predicted = sorted(predicted_prices)\n",
        "\n",
        "# Plot the original and predicted prices\n",
        "plt.plot(prices_original, marker='o', linestyle='', alpha=0.3)\n",
        "plt.plot(prices_predicted, color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
        "plt.ylabel(\"price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And this looks good, except for very cheap and very expensive diamonds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### More plots\n",
        "\n",
        "And since we can't see in 4D or 5D yet, let's just plot `price` as a function of a few individual features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot price vs carat, x, y and z\n",
        "for feat in [\"carat\", \"x\", \"y\", \"z\"]:\n",
        "  x = diamonds_df[feat]\n",
        "  prices_original = diamonds_df[\"price\"]\n",
        "  prices_predicted = predicted_prices\n",
        "\n",
        "  # Plot the original and predicted prices\n",
        "  plt.plot(x, prices_original, marker='o', linestyle='', alpha=0.3)\n",
        "  plt.plot(x, prices_predicted, color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
        "  plt.xlabel(feat)\n",
        "  plt.ylabel(\"price\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🎉🍾\n",
        "\n",
        "These look ok. We have a nice model for diamond prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## More Non-Linear Linear Regression!\n",
        "\n",
        "This is just a quick aside into the world of _**feature engineering**_, which is the process of carefully adding data to our dataset, based on data we already have.\n",
        "\n",
        "Let's repeat the process of linear regression for a new dataset for monthly diamond sales.\n",
        "\n",
        "We'll follow the same steps as before:\n",
        "1. Load data\n",
        "2. Encode\n",
        "3. Normalize\n",
        "4. Choose features\n",
        "5. Create model\n",
        "6. Test model on input data\n",
        "7. Measure error and analyze results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Load Dataset\n",
        "SALES_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/diamond_sales.json\"\n",
        "\n",
        "# Read into DataFrame\n",
        "sales_data = object_from_json_url(SALES_FILE)\n",
        "sales_df = pd.DataFrame.from_records(sales_data)\n",
        "\n",
        "# Look at features: values, types, names, min, max, mean\n",
        "for c in sales_df.columns:\n",
        "  print(c, \"\\n\\tmin:\", sales_df[c].min())\n",
        "  print(\"\\tmax:\", sales_df[c].max())\n",
        "  print(\"\\tavg:\", round(sales_df[c].mean(), 3))\n",
        "  print(\"\\tstd:\", round(sales_df[c].std(), 3))\n",
        "\n",
        "sales_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a much simpler dataset with only one feature: `month`, and one outcome: `sales`.\n",
        "\n",
        "We can easily plot all of the data just to check for any trends or specificities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(sales_df[\"month\"], sales_df[\"sales\"], marker='o', linestyle='', alpha=0.3)\n",
        "plt.title(\"monthly sales\")\n",
        "plt.xlabel(\"month\")\n",
        "plt.ylabel(\"sales\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like diamond sales to me !\n",
        "\n",
        "Despite the spread of sale amounts between $\\$1000$ and $\\$6000$, we can kind of notice a slightly upward trend.\n",
        "\n",
        "Let's check with a model.\n",
        "\n",
        "### Model\n",
        "\n",
        "Let's do linear regression to predict future diamond sales amounts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: train a Linear Regression predictor for sales based on month\n",
        "\n",
        "## 3. Normalize: we only have one input. No need.\n",
        "## 4. Separate the outcome variable and the independent variables\n",
        "## 5. Create a LinearRegression object and fit a model that relates sales amounts to month\n",
        "## 6. Run the model on the training data\n",
        "## 7. Measure error\n",
        "\n",
        "# Plot predictions\n",
        "plt.plot(sales_df[\"month\"], sales_df[\"sales\"], marker='o', linestyle='', alpha=0.3)\n",
        "plt.plot(sales_df[\"month\"], predicted_sales, marker='', color='r')\n",
        "plt.title(\"monthly sales\")\n",
        "plt.xlabel(\"month\")\n",
        "plt.ylabel(\"sales\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's our slight upward trend... and almost $\\$1000$ of average error.\n",
        "\n",
        "### Why we look at data\n",
        "\n",
        "Let's say that when we first plotted our data, instead of plotting dots with:\n",
        "\n",
        "```py\n",
        "plt.plot(sales_df[\"month\"], sales_df[\"sales\"], marker='o', linestyle='', alpha=0.3)\n",
        "```\n",
        "\n",
        "we left out some of the parameters and plotted this instead:\n",
        "\n",
        "```py\n",
        "plt.plot(sales_df[\"month\"], sales_df[\"sales\"], alpha=0.3)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(sales_df[\"month\"], sales_df[\"sales\"], alpha=0.3)\n",
        "plt.title(\"monthly sales\")\n",
        "plt.xlabel(\"month\")\n",
        "plt.ylabel(\"sales\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Same Data, Different Story\n",
        "\n",
        "We can now see that the ups and downs in the sales amounts aren't random, but probably correlate with the months of the year.\n",
        "\n",
        "Whenever we want to model data like this, we have to add a special type of feature to our data in order to capture the ups and downs of cyclic, periodic values.\n",
        "\n",
        "Just like we added new quadratic and cubic features to our linear regression equation, like this:\n",
        "\n",
        "$\\displaystyle sales = \\beta_0 \\cdot month + \\beta_1 \\cdot month^{2} + \\beta_2 \\cdot month^{3}$\n",
        "\n",
        "We can add a periodic feature by using periodic functions like `sin()` and `cos()`:\n",
        "\n",
        "$\\displaystyle sales = \\beta_0 \\cdot month + \\beta_1 \\cdot \\sin(month)$\n",
        "\n",
        "We just have to define a function and then create a new column in our `DataFrame` based on this function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import sin, pi\n",
        "\n",
        "# function with a period of 12 (months)\n",
        "def sinx(x):\n",
        "  return sin(2 * x * pi / 12.0)\n",
        "\n",
        "# create a new column called \"periodic_month\" by applying sinx() to all values of month\n",
        "sales_df[\"periodic_month\"] = sales_df[\"month\"].apply(sinx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Re-Model\n",
        "\n",
        "Everything from now on is the same. We can even copy+paste the code from above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: train a Linear Regression predictor for sales based on month\n",
        "\n",
        "## 3. Normalize\n",
        "## 4. Separate the outcome variable and the independent variables\n",
        "## 5. Create a LinearRegression object and fit it with training data\n",
        "## 6. Run the model on the training data\n",
        "## 7. Measure error\n",
        "\n",
        "# Plot predictions\n",
        "plt.plot(sales_df[\"month\"], sales_df[\"sales\"], marker='o', linestyle='-', alpha=0.3)\n",
        "plt.plot(sales_df[\"month\"], predicted_sales, marker='', color='r')\n",
        "plt.title(\"monthly sales\")\n",
        "plt.xlabel(\"month\")\n",
        "plt.ylabel(\"sales\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, just like that, our model's error got better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## More Regression!\n",
        "\n",
        "Let's do one more regression exercise using a different dataset.\n",
        "\n",
        "This one is for wine quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Load Dataset\n",
        "WINE_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/wines.json\"\n",
        "\n",
        "# Read into DataFrame\n",
        "wines_data = object_from_json_url(WINE_FILE)\n",
        "wines_df = pd.DataFrame.from_records(wines_data)\n",
        "\n",
        "# Look at features: values, types, names, etc\n",
        "wines_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeat some of the steps above to analyze the data\n",
        "\n",
        "Specifically, steps $3$: normalize and look at the covariance matrix using `quality` as the independent variable of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: normalize and look at covariance matrix\n",
        "\n",
        "## 3. Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Since this is a new dataset, let's peek at its covariance matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot\n",
        "\n",
        "Looks like `alcohol`, `density`, `chlorides` and `volatility` are the $4$ features that mostly contribute to the quality.\n",
        "\n",
        "Let's look at graphs of `quality` as a function of these $4$ features.\n",
        "\n",
        "This could be two $3D$ graphs of pairs of variables, but four $2D$ graphs is probably easier to read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot quality as a function of alcohol, acidity, density and chlorides\n",
        "for feat in [\"alcohol\", \"density\", \"chlorides\", \"volatility\"]:\n",
        "  plt.plot(wines_scaled_df[feat], wines_df[\"quality\"], marker=\"o\", color=\"r\", linestyle=\"\", alpha=0.4)\n",
        "  plt.xlabel(feat)\n",
        "  plt.ylabel(\"quality\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression\n",
        "\n",
        "Use the method above that we used in the diamond dataset to create a model that predicts wine `quality` as a function of **ALL** of its other features.\n",
        "\n",
        "Use all of our features to run regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a linear model and run regression\n",
        "\n",
        "## 4. Separate the outcome variable and the independent variables\n",
        "## 4B. Polynomial features\n",
        "## 5. Create a LinearRegression object and fit it with the training poly features\n",
        "## 6. Run the model on the training data\n",
        "## 7. Measure error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Results\n",
        "\n",
        "On average our predictions are within $0.57$ points of the real quality values.\n",
        "\n",
        "Run the cell below to look at some plots of our predictions. This assumes the predictions are in a variable called `predicted_quality`. Adjust if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot quality vs alcohol and volatile acidity\n",
        "for feat in [\"alcohol\", \"density\", \"chlorides\", \"volatility\"]:\n",
        "  x = wines_df[feat]\n",
        "  quality_original = wines_df[\"quality\"]\n",
        "\n",
        "  # Plot the original quality\n",
        "  plt.plot(x, quality_original, marker='o', linestyle='', alpha=0.3)\n",
        "  plt.plot(x, predicted_quality, color='r', marker='o', linestyle='', alpha=0.3)\n",
        "  plt.xlabel(feat)\n",
        "  plt.ylabel(\"quality\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "# 🤔\n",
        "\n",
        "Hmm.... these could be better.\n",
        "\n",
        "Our model wasn't able to capture the fact that the calculated `quality` value should be a discrete value and not a number with decimals.\n",
        "\n",
        "This is because our `quality` category is not continuous, and instead can only have particular discrete values.\n",
        "\n",
        "Instead of trying to calculate continuous values for `quality`, our model should really be trying to put the wines in the right `quality` category.\n",
        "\n",
        "Let's use a different type of model for this task.\n",
        "\n",
        "Instead of learning how to predict a continuous value from the independent variables, like this:\n",
        "\n",
        "<img src=\"./imgs/wages-exp-fit.png\" width=\"620px\"/>\n",
        "\n",
        "Our model should learn how to place data points into discrete groups, like this:\n",
        "\n",
        "<img src=\"./imgs/wages-exp-classes.png\" width=\"620px\"/>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "5020",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
